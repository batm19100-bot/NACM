import streamlit as st
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import plotly.graph_objects as go
import re
from collections import Counter
import os
import pickle
import hashlib
from datetime import datetime
import base64
import time
from io import BytesIO
from openpyxl.styles import PatternFill
from openpyxl.utils import get_column_letter
import warnings
warnings.filterwarnings('ignore')


def get_base64_of_bin_file(bin_file):
    """Convertit un fichier binaire en base64"""
    try:
        with open(bin_file, 'rb') as f:
            data = f.read()
        return base64.b64encode(data).decode()
    except:
        return None

def set_background_image(image_file):
    """D√©finit une image de fond avec overlay noir glacial"""
    bin_str = get_base64_of_bin_file(image_file)
    if bin_str:
        page_bg_img = f'''
        <style>
        .stApp {{
            background-image: url("data:image/png;base64,{bin_str}");
            background-size: cover;
            background-position: center;
            background-repeat: no-repeat;
            background-attachment: fixed;
        }}
        .stApp::before {{
            content: "";
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: linear-gradient(135deg, 
                rgba(0, 0, 0, 0.85) 0%, 
                rgba(10, 25, 40, 0.9) 25%, 
                rgba(0, 15, 30, 0.88) 50%, 
                rgba(5, 20, 35, 0.9) 75%, 
                rgba(0, 0, 0, 0.85) 100%);
            backdrop-filter: blur(1px);
            z-index: -1;
        }}
        </style>
        '''
        st.markdown(page_bg_img, unsafe_allow_html=True)




# Configuration de la page
st.set_page_config(
    page_title="Classifieur de l‚Äôactivit√© selon la nomenclature",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# D√©finir l'image de fond
image_path = os.path.join("images", "Structure.jpg")
#image_path = os.path.abspath(os.path.join("images", "Structure.jpg"))
if os.path.exists(image_path):
    set_background_image(image_path)

# Afficher les logos
col1, col2, col3 = st.columns([1, 4, 1])
with col1:
    logo1_path = os.path.join("images", "logo1.jpg")
    if os.path.exists(logo1_path):
        st.image(logo1_path, use_column_width=True)

with col3:
    logo2_path = os.path.join("images", "logo2.jpg")
    if os.path.exists(logo2_path):
        st.image(logo2_path, use_column_width=True)


def display_fixed_logos():
    """Affiche les logos fixes - logo1 √† gauche, logo2 √† droite - version ajust√©e"""
    logo1_str = get_base64_of_bin_file("logo1.png")
    logo2_str = get_base64_of_bin_file("logo2.png")
    
    if not logo1_str and not logo2_str:
        st.sidebar.info("Logos non trouv√©s. Placez logo1.png et logo2.png dans le r√©pertoire de l'application.")
        return
    
    # CSS avec position ajust√©e pour √©viter la barre Streamlit et taille augment√©e
    logos_css = """
    <style>
    .fixed-logo-left {
        position: fixed !important;
        top: 80px !important;
        left: 20px !important;
        z-index: 9999 !important;
        pointer-events: none !important;
    }
    
    .fixed-logo-right {
        position: fixed !important;
        top: 80px !important;
        right: 20px !important;
        z-index: 9999 !important;
        pointer-events: none !important;
    }
    
    .fixed-logo-left img, .fixed-logo-right img {
        height: 200px !important;
        width: auto !important;
        border-radius: 12px !important;
        box-shadow: 0 6px 20px rgba(0,0,0,0.4) !important;
        transition: all 0.3s ease !important;
        background: rgba(255,255,255,0.15) !important;
        padding: 8px !important;
        backdrop-filter: blur(10px) !important;
        border: 2px solid rgba(255,255,255,0.2) !important;
        display: block !important;
        pointer-events: auto !important;
    }
    
    .fixed-logo-left img:hover, .fixed-logo-right img:hover {
        transform: scale(1.05) !important;
        box-shadow: 0 8px 25px rgba(0,0,0,0.5) !important;
        background: rgba(255,255,255,0.2) !important;
    }
    
    /* Assurer la visibilit√© sur tous les th√®mes */
    .fixed-logo-left, .fixed-logo-right {
        background: transparent !important;
    }
    
    /* Adaptation responsive */
    @media (max-width: 768px) {
        .fixed-logo-left img, .fixed-logo-right img {
            height: 80px !important;
        }
        .fixed-logo-left {
            left: 10px !important;
        }
        .fixed-logo-right {
            right: 10px !important;
        }
    }
    </style>
    """
    
    st.markdown(logos_css, unsafe_allow_html=True)
    
    # Afficher les logos s√©par√©ment pour un meilleur contr√¥le
    if logo1_str:
        logo1_html = f'''
        <div class="fixed-logo-left">
            <img src="data:image/png;base64,{logo1_str}" alt="Logo 1" title="Institut National de la Statistique">
        </div>
        '''
        st.markdown(logo1_html, unsafe_allow_html=True)
    
    if logo2_str:
        logo2_html = f'''
        <div class="fixed-logo-right">
            <img src="data:image/png;base64,{logo2_str}" alt="Logo 2" title="Institut Sous-r√©gional de Statistique et d'√âconomie Appliqu√©e">
        </div>
        '''
        st.markdown(logo2_html, unsafe_allow_html=True)
    
    # Message de confirmation dans la sidebar

# D√©placer de mani√®re transitoire l'arri√®re plan
st.markdown("""
<style>
/* D√©calage du contenu principal */
[data-testid="stSidebar"][aria-expanded="true"] ~ div[data-testid="stAppViewContainer"] {
    margin-left: 250px;
    transition: margin-left 0.3s ease;
}
[data-testid="stSidebar"][aria-expanded="false"] ~ div[data-testid="stAppViewContainer"] {
    margin-left: 0;
    transition: margin-left 0.3s ease;
}

/* ‚úÖ Correction : d√©placement direct du logo gauche */
.fixed-logo-left {
    position: fixed !important;
    top: 80px !important;
    left: 20px !important;
    transition: left 0.3s ease !important;
    z-index: 9999 !important;
}

/* Quand la sidebar est ouverte (hack via parent [aria-expanded]) */
section[data-testid="stSidebar"][aria-expanded="true"] ~ div [class="fixed-logo-left"] {
    left: 270px !important; /* 250px + marge */
}

section[data-testid="stSidebar"][aria-expanded="true"] ~ div [class="fixed-logo-left"] {
    left: 270px !important;
    opacity: 0.85;
    transition: left 0.3s ease, opacity 0.3s ease;
}

</style>
""", unsafe_allow_html=True)

# Barre sup√©rieure
st.markdown("""
<style>
header[data-testid="stHeader"] {
    background-color: #567671 !important;
}
</style>
""", unsafe_allow_html=True)

# Barre de d√©filement
st.markdown("""
<style>
/* --- Sidebar Scrollbar --- */
section[data-testid="stSidebar"]::-webkit-scrollbar {
    width: 40px;
}
section[data-testid="stSidebar"]::-webkit-scrollbar-track {
    background: #08C478;
    border-radius: 40px;
}
section[data-testid="stSidebar"]::-webkit-scrollbar-thumb {
    background: linear-gradient(180deg, #4B0082, #8A2BE2);
    border-radius: 40px;
}
section[data-testid="stSidebar"]::-webkit-scrollbar-thumb:hover {
    background: linear-gradient(180deg, #5E11A3, #A15CF2);
}

/* --- Contenu principal Scrollbar --- */
div[data-testid="stAppViewContainer"]::-webkit-scrollbar {
    width: 40px;
}
div[data-testid="stAppViewContainer"]::-webkit-scrollbar-thumb {
    background-color: #444;
    border-radius: 40px;
}
div[data-testid="stAppViewContainer"]::-webkit-scrollbar-thumb:hover {
    background-color: #777;
}
</style>
""", unsafe_allow_html=True)


def load_css():
    st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600;700&display=swap');
        
        * {
            font-family: 'Poppins', sans-serif;
        }
        
        .main-header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 3rem 2rem;
            border-radius: 20px;
            margin-bottom: 2rem;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            animation: slideInDown 0.8s ease-out;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.2);
        }
        
        .main-header h1 {
            color: white;
            text-align: center;
            margin: 0;
            font-size: 3rem;
            font-weight: 700;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .main-header p {
            color: rgba(255,255,255,0.9);
            text-align: center;
            font-size: 1.3rem;
            margin: 1rem 0 0 0;
        }
        
        /* Am√©lioration de la lisibilit√© de la sidebar */
        .css-1d391kg {
            background-color: rgba(248, 250, 252, 0.98) !important;
        }
        
        .stSidebar {
            background-color: rgba(248, 250, 252, 0.98) !important;
        }
        
        .stSidebar .stMarkdown {
            color: #1a202c !important;
        }
        
        .stSidebar h1, .stSidebar h2, .stSidebar h3, .stSidebar h4, .stSidebar h5, .stSidebar h6 {
            color: #2d3748 !important;
            text-shadow: none !important;
            font-weight: 600 !important;
        }
        
        .stSidebar p, .stSidebar span, .stSidebar div, .stSidebar label {
            color: #2d3748 !important;
            font-weight: 500 !important;
        }
        
        /* Am√©lioration des selectbox */
        .stSidebar .stSelectbox > div > div {
            background: #ffffff !important;
            color: #1a202c !important;
            border: 2px solid #cbd5e0 !important;
            border-radius: 8px !important;
            font-weight: 500 !important;
        }
        
        .stSidebar .stSelectbox > div > div > div {
            color: #1a202c !important;
            font-weight: 500 !important;
        }
        
        .stSidebar .stSelectbox > div > div:hover {
            border-color: #667eea !important;
            box-shadow: 0 0 0 1px #667eea !important;
        }
        
        /* Am√©lioration des checkbox */
        .stSidebar .stCheckbox > label {
            color: #2d3748 !important;
            font-weight: 500 !important;
        }
        
        .stSidebar .stCheckbox > label > span {
            color: #2d3748 !important;
            font-weight: 500 !important;
        }
        
        /* Am√©lioration des boutons dans la sidebar */
        .stSidebar .stButton > button {
            background: #667eea !important;
            color: #ffffff !important;
            border: none !important;
            border-radius: 8px !important;
            font-weight: 600 !important;
            transition: all 0.2s ease !important;
        }
        
        .stSidebar .stButton > button:hover {
            background: #5a67d8 !important;
            transform: translateY(-1px) !important;
        }
        
        /* Am√©lioration des file uploader */
        .stSidebar .stFileUploader > div {
            background: #ffffff !important;
            border: 2px dashed #cbd5e0 !important;
            border-radius: 8px !important;
        }
        
        .stSidebar .stFileUploader label {
            color: #2d3748 !important;
            font-weight: 500 !important;
        }
        
        /* Am√©lioration des alertes dans la sidebar */
        .stSidebar .stAlert {
            background: #ffffff !important;
            color: #2d3748 !important;
            border-radius: 8px !important;
            border-left: 4px solid #667eea !important;
        }
        
        .stSidebar .stSuccess {
            background: #f0fff4 !important;
            color: #22543d !important;
            border-left-color: #38a169 !important;
        }
        
        .stSidebar .stWarning {
            background: #fffbf0 !important;
            color: #744210 !important;
            border-left-color: #d69e2e !important;
        }
        
        .stSidebar .stError {
            background: #fff5f5 !important;
            color: #742a2a !important;
            border-left-color: #e53e3e !important;
        }
        
        .stSidebar .stInfo {
            background: #ebf8ff !important;
            color: #2a4365 !important;
            border-left-color: #3182ce !important;
        }
        
        /* Am√©lioration des expandeurs */
        .stSidebar .stExpander {
            background: #ffffff !important;
            border: 1px solid #e2e8f0 !important;
            border-radius: 8px !important;
        }
        
        .stSidebar .stExpander > div > div > div {
            color: #2d3748 !important;
            font-weight: 500 !important;
        }
        
        /* Am√©lioration du text input et text area */
        .stSidebar .stTextInput > div > div > input {
            background: #ffffff !important;
            color: #1a202c !important;
            border: 2px solid #cbd5e0 !important;
            border-radius: 8px !important;
        }
        
        .stSidebar .stTextArea > div > div > textarea {
            background: #ffffff !important;
            color: #1a202c !important;
            border: 2px solid #cbd5e0 !important;
            border-radius: 8px !important;
        }
        
        /* Am√©lioration globale des √©l√©ments de la sidebar */
        .stSidebar .element-container {
            color: #2d3748 !important;
        }
        
        .stSidebar .markdown-text-container {
            color: #2d3748 !important;
        }
        
        .level-card {
            background: rgba(15, 25, 35, 0.95);
            color: #ffffff;
            padding: 2rem;
            border-radius: 15px;
            border-left: 5px solid #007bff;
            margin: 1.5rem 0;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
            transition: all 0.3s ease;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.1);
        }
        
        .prediction-result {
            background: rgba(15, 35, 25, 0.95);
            color: #ffffff;
            padding: 2rem;
            border-radius: 15px;
            border: 3px solid #28a745;
            margin: 1.5rem 0;
            backdrop-filter: blur(10px);
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        }
        
        .hierarchy-selector {
            background: rgba(255, 255, 255, 0.9);
            color: #1f2937;
            padding: 1.5rem;
            border-radius: 15px;
            border: 2px solid rgba(107, 114, 128, 0.2);
            margin: 1rem 0;
            backdrop-filter: blur(10px);
        }
        
        .update-section {
            background: rgba(15, 35, 25, 0.95);
            color: #ffffff;
            padding: 1.5rem;
            border-radius: 15px;
            border: 2px solid #28a745;
            margin: 1rem 0;
            backdrop-filter: blur(10px);
        }
        
        .batch-section {
            background: rgba(25, 15, 35, 0.95);
            color: #ffffff;
            padding: 1.5rem;
            border-radius: 15px;
            border: 2px solid #764ba2;
            margin: 1rem 0;
            backdrop-filter: blur(10px);
        }
        
        .hierarchy-info {
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.3) 0%, rgba(118, 75, 162, 0.3) 100%);
            padding: 1rem;
            border-radius: 10px;
            border: 1px solid rgba(255,255,255,0.2);
            margin: 0.5rem 0;
        }
        
        /* Am√©lioration des selectbox globales */
        .stSelectbox > div > div {
            background: #ffffff !important;
            color: #1a202c !important;
            border: 2px solid #cbd5e0 !important;
            border-radius: 8px !important;
            font-weight: 500 !important;
        }
        
        .stSelectbox > div > div > div {
            color: #1a202c !important;
            font-weight: 500 !important;
        }
        
        .stSelectbox > div > div:hover {
            border-color: #667eea !important;
            box-shadow: 0 0 0 1px #667eea !important;
        }
        
        /* Am√©lioration des text areas globales */
        .stTextArea > div > div > textarea {
            background: #ffffff !important;
            color: #1a202c !important;
            border: 2px solid #cbd5e0 !important;
            border-radius: 8px !important;
            font-weight: 500 !important;
        }
        
        .stTextArea > div > div > textarea::placeholder {
            color: #718096 !important;
            font-weight: 400 !important;
        }
        
        .stTextArea > div > div > textarea:focus {
            border-color: #667eea !important;
            box-shadow: 0 0 0 1px #667eea !important;
        }
        
        /* Am√©lioration des dataframes */
        .stDataFrame {
            background: #ffffff !important;
            border-radius: 8px !important;
            overflow: hidden !important;
        }
        
        .stDataFrame table {
            color: #1a202c !important;
        }
        
        .stDataFrame th {
            background: #f7fafc !important;
            color: #2d3748 !important;
            font-weight: 600 !important;
        }
        
        .stDataFrame td {
            color: #2d3748 !important;
        }
        
        /* Am√©lioration des m√©triques et informations */
        .metric-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem;
            border-radius: 15px;
            text-align: center;
            margin: 1rem 0;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            transition: all 0.3s ease;
        }
        
        .hierarchy-info {
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.1) 0%, rgba(118, 75, 162, 0.1) 100%);
            color: #1a202c;
            padding: 1rem;
            border-radius: 10px;
            border: 2px solid rgba(102, 126, 234, 0.2);
            margin: 0.5rem 0;
        }
        
        /* Am√©lioration des sections color√©es */
        .hierarchy-selector {
            background: rgba(255, 255, 255, 0.95);
            color: #1a202c;
            padding: 1.5rem;
            border-radius: 15px;
            border: 2px solid rgba(102, 126, 234, 0.2);
            margin: 1rem 0;
            backdrop-filter: blur(10px);
        }
        
        .update-section {
            background: rgba(240, 253, 244, 0.95);
            color: #1a202c;
            padding: 1.5rem;
            border-radius: 15px;
            border: 2px solid #68d391;
            margin: 1rem 0;
            backdrop-filter: blur(10px);
        }
        
        .batch-section {
            background: rgba(252, 245, 255, 0.95);
            color: #1a202c;
            padding: 1.5rem;
            border-radius: 15px;
            border: 2px solid #b794f6;
            margin: 1rem 0;
            backdrop-filter: blur(10px);
        }
        
        /* Am√©lioration des file uploaders globaux */
        .stFileUploader > div {
            background: #ffffff !important;
            border: 2px dashed #cbd5e0 !important;
            border-radius: 8px !important;
        }
        
        .stFileUploader label {
            color: #2d3748 !important;
            font-weight: 500 !important;
        }
        
        /* Am√©lioration des sliders */
        .stSlider > div > div > div > div {
            background: #667eea !important;
        }
        
        .stSlider > div > div > div > div > div {
            background: #667eea !important;
        }
        
        /* Am√©lioration des expander globaux */
        .stExpander {
            background: #ffffff !important;
            border: 1px solid #e2e8f0 !important;
            border-radius: 8px !important;
        }
        
        .stExpander > div > div > div {
            color: #2d3748 !important;
            font-weight: 500 !important;
        }
        
        /* Am√©lioration des colonnes et containers */
        .element-container {
            color: #2d3748 !important;
        }
        
        .markdown-text-container {
            color: #2d3748 !important;
        }
        
        /* Am√©lioration du contraste pour les labels */
        label {
            color: #2d3748 !important;
            font-weight: 500 !important;
        }
        
        .confidence-high { color: #28a745; font-weight: bold; }
        .confidence-medium { color: #ffc107; font-weight: bold; }
        .confidence-low { color: #dc3545; font-weight: bold; }
        
        h1, h2, h3, h4, h5, h6 { color: #ffffff !important; text-shadow: 2px 2px 4px rgba(0,0,0,0.5); }
        .stMarkdown { color: #ffffff; }
        p, span, div { color: #ffffff !important; }

        /* Info-bulles et tooltips : fond sombre, texte blanc pour meilleur contraste (sans bordures) */
        [data-baseweb="tooltip"],
        [data-baseweb="popover"],
        .stTooltipIcon > span,
        div[data-testid="stToolbar"] span {
            color: #ffffff !important;
            font-size: 1.02rem !important;
            font-weight: 600 !important;
            line-height: 1.4 !important;
            background: rgba(10, 10, 12, 0.90) !important;
            padding: 0.6rem 0.9rem !important;
            border-radius: 8px !important;
            border: 0 !important;
            outline: none !important;
            box-shadow: 0 8px 24px rgba(0, 0, 0, 0.6) !important;
            max-width: 360px !important;
            backdrop-filter: blur(6px) !important;
            text-shadow: none !important;
            margin: 4px !important;
        }

        /* Style sp√©cifique pour les tooltips Streamlit (contenu) - sans bordure */
        .stTooltipContent {
            background-color: rgba(10, 10, 12, 0.90) !important;
            color: #ffffff !important;
            border: 0 !important;
            outline: none !important;
            padding: 0.6rem !important;
            box-shadow: 0 8px 24px rgba(0, 0, 0, 0.6) !important;
            max-width: 360px !important;
        }

        /* Ic√¥ne d'info : blanche pour contraste */
        [data-testid="stTooltipIcon"] > svg {
            fill: #ffffff !important;
            width: 20px !important;
            height: 20px !important;
            border: none !important;
        }

        .streamlit-expanderHeader:hover [data-testid="stTooltipIcon"] > svg {
            fill: #ffffff !important;
        }
        
        .stButton > button {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            padding: 0.75rem 2rem;
            border-radius: 25px;
            font-weight: 600;
            transition: all 0.3s ease;
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }
        
        .stButton > button:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 25px rgba(0,0,0,0.3);
        }
    </style>
    """, unsafe_allow_html=True)

st.markdown("""
    <style>
    /* ‚úÖ Bo√Æte de texte plus lisible */
    textarea, .stTextArea textarea {
        background-color: #ffffff !important;
        color: #000000 !important;
        font-size: 16px !important;
    }

    /* ‚úÖ Boutons mieux visibles */
    .stButton>button {
        background-color: #6c63ff !important;
        color: white !important;
        border-radius: 10px !important;
        font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

class EnhancedHierarchicalPredictor:
    def __init__(self):
        self.vectorizer = TfidfVectorizer(
            max_features=10000,
            ngram_range=(1, 3),
            lowercase=True,
            analyzer='word',
            min_df=1,
            max_df=0.95
        )
        
        # Mod√®le unique pour CPU - MultinomialNB seulement
        self.base_models = {
            'Naive Bayes': MultinomialNB()#,
#            'Logistic Regression': LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto')
        }
        
        # Grille de param√®tres simplifi√©e
        self.param_grids = {
            'Naive Bayes': {'alpha': [0.1, 0.5, 1.0]}#,
#                 'Logistic Regression': {'C': [0.1, 1.0, 5.0], 'class_weight': [None, 'balanced']
#            }
        }
        
        # Structures de suivi
        self.label_encoders = {}
        self.hierarchy_predictors = {}
        self.best_models = {}
        self.hierarchy_structure = {}
        self.models_directory = "saved_models"
        self.use_smote = True
        
        if not os.path.exists(self.models_directory):
            os.makedirs(self.models_directory)
    
    # ----------------------------------------------------------------
    # UTILS
    # ----------------------------------------------------------------

    def get_data_hash(self, df):
        """G√©n√®re un hash unique pour les donn√©es"""
        data_string = pd.util.hash_pandas_object(df[['reponse', 'Classe', 'Grand poste', 'Section', 'Groupe']], index=True).values
        return hashlib.md5(str(data_string).encode()).hexdigest()[:8]
    
    def get_model_filename(self, data_hash, prediction_level):
        """G√©n√®re le nom de fichier pour sauvegarder le mod√®le"""
        return os.path.join(self.models_directory, f"enhanced_predictor_{prediction_level}_{data_hash}.pkl")
    
    def save_models(self, filename):
        """Sauvegarde tous les mod√®les et encodeurs optimis√©s"""
        model_data = {
            'vectorizer': self.vectorizer,
            'label_encoders': self.label_encoders,
            'hierarchy_predictors': self.hierarchy_predictors,
            'best_models': self.best_models,
            'hierarchy_structure': self.hierarchy_structure,
            'timestamp': datetime.now().isoformat(),
            'use_smote': self.use_smote
        }
        
        with open(filename, 'wb') as f:
            pickle.dump(model_data, f)
        
        st.success(f"Meilleurs mod√®les sauvegard√©s: {filename}")
    
    def load_models(self, filename):
        """Charge les mod√®les sauvegard√©s"""
        try:
            with open(filename, 'rb') as f:
                model_data = pickle.load(f)
            
            self.vectorizer = model_data['vectorizer']
            self.label_encoders = model_data['label_encoders']
            self.hierarchy_predictors = model_data.get('hierarchy_predictors', {})
            self.best_models = model_data.get('best_models', {})
            self.hierarchy_structure = model_data.get('hierarchy_structure', {})
            self.use_smote = model_data.get('use_smote', True)
            
            timestamp = model_data.get('timestamp', 'Inconnu')
            st.success(f"Mod√®les optimis√©s charg√©s (sauvegard√©s le: {timestamp[:19]})")
            return True
        except Exception as e:
            st.warning(f"Impossible de charger les mod√®les: {e}")
            return False
    
    def models_exist(self, filename):
        """V√©rifie si les mod√®les sauvegard√©s existent"""
        return os.path.exists(filename)
    
    # ----------------------------------------------------------------
    # STRUCTURE HI√âRARCHIQUE
    # ----------------------------------------------------------------

    def build_hierarchy_structure(self, df):
        """Construit la structure hi√©rarchique compl√®te"""
        hierarchy_levels = ['Grand poste', 'Section', 'Groupe', 'Classe']
        self.hierarchy_structure = {}
        
        for _, row in df.iterrows():
            current_level = self.hierarchy_structure
            
            for level in hierarchy_levels:
                value = row[level]
                if value not in current_level:
                    current_level[value] = {}
                current_level = current_level[value]
        
        return self.hierarchy_structure
    
    def get_filtered_options(self, level, parent_selections):
        """Obtient les options filtr√©es pour un niveau donn√© bas√© sur les s√©lections parentes"""
        hierarchy_levels = ['Grand poste', 'Section', 'Groupe', 'Classe']
        level_index = hierarchy_levels.index(level)
        
        current_structure = self.hierarchy_structure
        
        # Naviguer dans la structure selon les s√©lections parentes
        for i in range(level_index):
            parent_level = hierarchy_levels[i]
            if parent_level in parent_selections and parent_selections[parent_level]:
                if parent_selections[parent_level] in current_structure:
                    current_structure = current_structure[parent_selections[parent_level]]
                else:
                    return []
        
        return list(current_structure.keys()) if isinstance(current_structure, dict) else []
    
    def get_unique_prediction_path(self, selections):
        """V√©rifie si le chemin s√©lectionn√© m√®ne √† une classe unique"""
        hierarchy_levels = ['Grand poste', 'Section', 'Groupe', 'Classe']
        current_structure = self.hierarchy_structure
        
        for level in hierarchy_levels:
            if level in selections and selections[level]:
                if selections[level] in current_structure:
                    current_structure = current_structure[selections[level]]
                    
                    # Si nous sommes au niveau Classe et qu'il n'y a qu'une seule option
                    if level == 'Classe' and len(current_structure) == 0:
                        return True, selections[level]
                    elif level != 'Classe' and isinstance(current_structure, dict) and len(current_structure) == 1:
                        # S'il n'y a qu'une seule option au niveau suivant
                        next_level_index = hierarchy_levels.index(level) + 1
                        if next_level_index < len(hierarchy_levels):
                            next_level = hierarchy_levels[next_level_index]
                            return False, list(current_structure.keys())[0]
                else:
                    return False, None
        
        return False, None
    
    # ----------------------------------------------------------------
    # PR√âTRAITEMENT
    # ----------------------------------------------------------------
    def preprocess_text(self, text, language='auto'):
        """Preprocessing du texte adapt√© √† la langue"""
        text = str(text).lower()
        text = re.sub(r'[^\w\s\√†√¢√§√©√®√™√´√Ø√Æ√¥√∂√π√ª√º√ø√±√ß]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        return text
    
    def check_class_imbalance(self, y, threshold=0.1):
        """V√©rifie le d√©s√©quilibre des classes"""
        class_counts = Counter(y)
        total_samples = len(y)
        min_class_ratio = min(class_counts.values()) / total_samples
        
        if min_class_ratio < threshold:
            return True
        return False
    
    def prepare_data(self, df, prediction_level='Classe'):
        """Pr√©paration des donn√©es"""
        df['reponse_clean'] = df.apply(
            lambda row: self.preprocess_text(row['reponse'], row.get('langage', 'auto')), 
            axis=1
        )
        
        # Construire la structure hi√©rarchique
        self.build_hierarchy_structure(df)
        
        hierarchy_levels = ['Grand poste', 'Section', 'Groupe', 'Classe']
        target_levels = hierarchy_levels[:hierarchy_levels.index(prediction_level) + 1]
        
        for level in target_levels:
            if level not in self.label_encoders:
                le = LabelEncoder()
                df[f'{level}_encoded'] = le.fit_transform(df[level])
                self.label_encoders[level] = le
        
        return df
    
    # ----------------------------------------------------------------
    # ENTRA√éNEMENT AVEC PRISE EN COMPTE DES CORRECTIONS
    # ----------------------------------------------------------------

    def train_hierarchical_models(self, df, prediction_level='Classe'):
        """Compare Naive Bayes et Logistic Regression √† chaque niveau hi√©rarchique"""
        # üîÅ Recalcul complet du TF-IDF (int√®gre les corrections)
        self.vectorizer = TfidfVectorizer(
            max_features=10000, ngram_range=(1, 3),
            lowercase=True, analyzer='word', min_df=1, max_df=0.95
        )

        X = self.vectorizer.fit_transform(df['reponse_clean'])
        hierarchy_levels = ['Grand poste', 'Section', 'Groupe', 'Classe']
        target_levels = hierarchy_levels[:hierarchy_levels.index(prediction_level) + 1]

        progress_bar = st.progress(0)
        status = st.empty()

        for idx, level in enumerate(target_levels):
            status.info(f"üîÑ Entra√Ænement au niveau: {level}")
            progress_bar.progress((idx + 1) / len(target_levels))

            encoded_col = f'{level}_encoded'
            if encoded_col not in df.columns:
                continue

            y = df[encoded_col]
            if len(y.unique()) < 2:
                st.warning(f"Pas assez de classes pour {level}")
                continue

            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )

#            if predictor.use_smote:
#                smote = SMOTE(random_state=42)
#                X_train, y_train = smote.fit_resample(X_train, y_train)

            best_model, best_name, best_score = None, None, 0.0
            for model_name, model in self.base_models.items():
                param_grid = {f"classifier__{k}": v for k, v in self.param_grids[model_name].items()}
                pipeline = Pipeline([('classifier', model)])
                grid = GridSearchCV(
                    pipeline, param_grid, cv=StratifiedKFold(3, shuffle=True, random_state=42),
                    scoring='f1_weighted', n_jobs=1
                )
                grid.fit(X_train, y_train)
                if grid.best_score_ > best_score:
                    best_model, best_name, best_score = grid.best_estimator_, model_name, grid.best_score_

            self.best_models[level] = {
                'name': best_name,
                'model': best_model,
                'score': best_score
            }
            st.success(f"‚úÖ {level}")
            st.success(f"‚úÖ {level}: {best_name} (F1={best_score:.3f})")


        progress_bar.empty()
        status.empty()

        # Initialisation des encodeurs de labels pour chaque niveau
#        label_encoders = {}
        
#        for level in target_levels:
#            if level not in label_encoders:
#                le = LabelEncoder()
#                df[f'{level}_encoded'] = le.fit_transform(df[level])
#                label_encoders[level] = le  # Conserver l'encodeur pour une utilisation ult√©rieure

        # Calculer et afficher le rapport de classification
        y_pred = best_model.predict(X_test)
        report = classification_report(y_test, y_pred)#, target_names=le.classes_)
        st.markdown("### Rapport de Classification")
        st.text(report)

    # ----------------------------------------------------------------
    # PR√âDICTION
    # ----------------------------------------------------------------

    def predict_hierarchy(self, text, prediction_level='Classe'):
        text_clean = self.preprocess_text(text)
        X = self.vectorizer.transform([text_clean])
        predictions, probabilities = {}, {}
        hierarchy_levels = ['Grand poste', 'Section', 'Groupe', 'Classe']
        target_levels = hierarchy_levels[:hierarchy_levels.index(prediction_level) + 1]

        for level in target_levels:
            if level not in self.best_models:
                predictions[level] = "Non disponible"
                probabilities[level] = 0.0
                continue

            model = self.best_models[level]['model']
            pred = model.predict(X)[0]
            proba = model.predict_proba(X)[0] if hasattr(model, 'predict_proba') else [1.0]
            label = self.label_encoders[level].inverse_transform([pred])[0]
            confidence = max(proba) if len(proba) > 0 else 0.0

            predictions[level] = label
            probabilities[level] = confidence

        return predictions, probabilities


def create_hierarchy_selector(df, predictor):
    """Cr√©e les s√©lecteurs hi√©rarchiques avanc√©s dans la sidebar"""
    st.sidebar.markdown("### üéØ S√©lection Hi√©rarchique")
    
    hierarchy_levels = ['Grand poste', 'Section', 'Groupe', 'Classe']
    selections = {}
    
    # Section d'information sur la structure hi√©rarchique (simplifi√©e)
    with st.sidebar.expander("üìä Niveaux disponibles", expanded=False):
        for level in hierarchy_levels:
            unique_count = df[level].nunique()
            st.markdown(f"**{level}:** {unique_count} cat√©gories")
    
    st.sidebar.markdown("---")
    
    # S√©lecteurs hi√©rarchiques progressifs
    for i, level in enumerate(hierarchy_levels):
        if hasattr(predictor, 'hierarchy_structure') and predictor.hierarchy_structure:
            available_options = predictor.get_filtered_options(level, selections)
        else:
            if i == 0:
                available_options = sorted(df[level].unique())
            else:
                parent_level = hierarchy_levels[i-1]
                if parent_level in selections and selections[parent_level]:
                    filtered_df = df[df[parent_level] == selections[parent_level]]
                    available_options = sorted(filtered_df[level].unique())
                else:
                    available_options = []
        
        if available_options:
            options_with_all = ["-- Tous --"] + available_options
            
            selected = st.sidebar.selectbox(
                f"üîπ {level}",
                options=options_with_all,
                key=f"selector_{level}",
                help=f"Choisissez une cat√©gorie pour {level}"
            )
            
            if selected != "-- Tous --":
                selections[level] = selected
                
                if hasattr(predictor, 'hierarchy_structure'):
                    is_unique, unique_class = predictor.get_unique_prediction_path(selections)
                    if is_unique:
                        st.sidebar.success("‚úÖ Classification unique identifi√©e")
        else:
            if i > 0:
                st.sidebar.warning("‚ö†Ô∏è Aucune option disponible")
            break
    
    return selections

def process_batch_file(file_data, text_column):
    """Traite un fichier pour la pr√©diction par lot"""
    try:
        if file_data.name.endswith('.csv'):
            df = pd.read_csv(file_data)
        elif file_data.name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(file_data)
        elif file_data.name.endswith('.txt'):
            content = file_data.read().decode('utf-8')
            texts = [line.strip() for line in content.split('\n') if line.strip()]
            df = pd.DataFrame({'texte': texts})
            text_column = 'texte'
        else:
            return None, None, "Format de fichier non support√©"
        
        if text_column not in df.columns:
            return None, None, f"Colonne '{text_column}' introuvable"
        
        texts = df[text_column].dropna().astype(str).tolist()
        return df, texts, None
        
    except Exception as e:
        return None, None, f"Erreur lors du traitement: {e}"

def create_batch_results_table(texts, predictions, probabilities, prediction_level):
    """Cr√©e un tableau des r√©sultats de pr√©diction par lot"""
    hierarchy_levels = ['Grand poste', 'Section', 'Groupe', 'Classe']
    display_levels = hierarchy_levels[:hierarchy_levels.index(prediction_level) + 1]
    
    results_data = []
    for i, text in enumerate(texts):
        row = {'Texte': text[:100] + '...' if len(text) > 100 else text}
        
        for level in display_levels:
            if i < len(predictions) and level in predictions[i]:
                row[f'{level}'] = predictions[i][level]
                row[f'Confiance_{level}'] = f"{probabilities[i][level]:.2%}"
        
        results_data.append(row)
    
    return pd.DataFrame(results_data)

def create_prediction_analysis(predictions, probabilities, hierarchy_levels, selected_categories=None):
    """Cr√©e une analyse d√©taill√©e des pr√©dictions"""
    st.markdown("### üéØ Analyse D√©taill√©e des Pr√©dictions")
    
    # Cr√©er les donn√©es pour l'exportation
    comparison_data = []
    
    if selected_categories:
        st.markdown("#### üìä Comparaison Pr√©diction vs S√©lection")
        
        for level in hierarchy_levels:
            pred_value = predictions.get(level, "Non pr√©dit")
            selected_value = selected_categories.get(level, "Non s√©lectionn√©")
            confidence = probabilities.get(level, 0.0)
            
            is_match = pred_value == selected_value
            match_icon = "‚úÖ" if is_match else "‚ùå"
            
            comparison_data.append({
                "Niveau": level,
                "Pr√©diction": pred_value,
                "S√©lection": selected_value,
                "Confiance": f"{confidence:.2%}",
                "Correspondance": f"{match_icon} {'Oui' if is_match else 'Non'}"
            })
        
        comparison_df = pd.DataFrame(comparison_data)
        st.dataframe(comparison_df, use_container_width=True)
        
        # Ajouter un bouton d'export
        if st.button("üì• Exporter les r√©sultats"):
            try:
                from export_utils import export_to_excel
                output_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "exports")
                filename = export_to_excel(comparison_data, output_dir)
                st.success(f"‚úÖ R√©sultats export√©s avec succ√®s! Fichier: {filename}")
                full_path = os.path.join(output_dir, filename)
                with open(full_path, "rb") as file:
                    st.download_button(
                        label="üìé T√©l√©charger le fichier Excel",
                        data=file,
                        file_name=filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            except Exception as e:
                st.error(f"Erreur lors de l'exportation: {str(e)}")
        
        matches = sum(1 for level in hierarchy_levels 
                     if predictions.get(level) == selected_categories.get(level) and 
                        predictions.get(level) not in ["Non pr√©dit", "Mod√®le non disponible"])
        total_compared = sum(1 for level in hierarchy_levels 
                           if predictions.get(level) not in ["Non pr√©dit", "Mod√®le non disponible"] and 
                              selected_categories.get(level) != "Non s√©lectionn√©")
        
        if total_compared > 0:
            match_percentage = (matches / total_compared) * 100
            if match_percentage >= 80:
                st.success(f"üéØ Excellente correspondance: {match_percentage:.1f}% ({matches}/{total_compared})")
            elif match_percentage >= 60:
                st.warning(f"‚ö†Ô∏è Correspondance moyenne: {match_percentage:.1f}% ({matches}/{total_compared})")
            else:
                st.error(f"‚ùå Faible correspondance: {match_percentage:.1f}% ({matches}/{total_compared})")
    
    # Analyse de confiance par niveau
    st.markdown("#### üìà Analyse de Confiance")
    confidence_data = []
    
    for level in hierarchy_levels:
        if level in predictions and level in probabilities:
            confidence = probabilities[level]
            if confidence > 0:
                confidence_data.append({
                    "Niveau": level,
                    "Confiance": confidence,
                    "Pr√©diction": predictions[level]
                })
    
    if confidence_data:
        conf_df = pd.DataFrame(confidence_data)
        
        fig_conf = go.Figure(data=[
            go.Bar(
                x=conf_df["Niveau"],
                y=conf_df["Confiance"],
                text=[f"{conf:.2%}" for conf in conf_df["Confiance"]],
                textposition='auto',
                marker_color=['#28a745' if conf > 0.8 else '#ffc107' if conf > 0.6 else '#dc3545' 
                             for conf in conf_df["Confiance"]]
            )
        ])
        
        fig_conf.update_layout(
            title="Niveaux de Confiance par Niveau Hi√©rarchique",
            xaxis_title="Niveaux",
            yaxis_title="Confiance",
            yaxis=dict(tickformat=".0%"),
            height=400,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        
        st.plotly_chart(fig_conf, use_container_width=True)

#def update_model_with_corrections(predictor, df_prepared, corrections, prediction_level):
#    """Met √† jour le mod√®le avec les corrections fournies"""
#    try:
#        new_data = []
#        for correction in corrections:
#            new_data.append({
#                'reponse': correction['texte'],
#                'reponse_clean': predictor.preprocess_text(correction['texte']),
#                'Grand poste': correction.get('Grand poste', ''),
#                'Section': correction.get('Section', ''),
#                'Groupe': correction.get('Groupe', ''),
#                'Classe': correction.get('Classe', '')
#            })
#        
#        correction_df = pd.DataFrame(new_data)
#        updated_df = pd.concat([df_prepared, correction_df], ignore_index=True)
#        
#        hierarchy_levels = ['Grand poste', 'Section', 'Groupe', 'Classe']
#        target_levels = hierarchy_levels[:hierarchy_levels.index(prediction_level) + 1]
#        
#        for level in target_levels:
#            if level in predictor.label_encoders:
#                le = predictor.label_encoders[level]
#                all_classes = sorted(set(list(le.classes_) + list(updated_df[level].unique())))
#                
#                from sklearn.preprocessing import LabelEncoder
#                new_le = LabelEncoder()
#                new_le.fit(all_classes)
#                predictor.label_encoders[level] = new_le
#                
#                updated_df[f'{level}_encoded'] = new_le.transform(updated_df[level])
#        
#        predictor.vectorizer = TfidfVectorizer(
#            max_features=5000,
#            ngram_range=(1, 3),
#            lowercase=True,
#            analyzer='word',
#            min_df=2,
#            max_df=0.95
#    )
#        predictor.train_hierarchical_models(updated_df, prediction_level)
#        
#        return updated_df, True
#        
#    except Exception as e:
#        st.error(f"Erreur lors de la mise √† jour: {e}")
#        return df_prepared, False

def update_model_with_corrections(predictor, df_prepared, corrections, prediction_level):
    """Met √† jour le mod√®le avec les corrections fournies."""
    try:
        new_data = []
        for correction in corrections:
            new_data.append({
                'reponse': correction['texte'],
                'reponse_clean': predictor.preprocess_text(correction['texte']),
                'Grand poste': correction.get('Grand poste', ''),
                'Section': correction.get('Section', ''),
                'Groupe': correction.get('Groupe', ''),
                'Classe': correction.get('Classe', '')
            })
        
        correction_df = pd.DataFrame(new_data)
        updated_df = pd.concat([df_prepared, correction_df], ignore_index=True)

        # Re-encoder toutes les classes dans le DataFrame mis √† jour
        hierarchy_levels = ['Grand poste', 'Section', 'Groupe', 'Classe']
        for level in hierarchy_levels:
            if level in predictor.label_encoders:
                le = predictor.label_encoders[level]
                all_classes = sorted(set(list(le.classes_) + list(updated_df[level].unique())))
                
                new_le = LabelEncoder()
                new_le.fit(all_classes)
                updated_df[f'{level}_encoded'] = new_le.transform(updated_df[level])
                predictor.label_encoders[level] = new_le

        # R√©entra√Æner le mod√®le sur les donn√©es mises √† jour
        predictor.train_hierarchical_models(updated_df, prediction_level)
        
        # Sauvegarde du mod√®le
        data_hash = predictor.get_data_hash(updated_df)
        model_filename = predictor.get_model_filename(data_hash, prediction_level)
        predictor.save_models(model_filename)  # Sauvegarde des mod√®les

        st.success("üéØ Mod√®le mis √† jour et sauvegard√© avec succ√®s !")
        return updated_df, True

    except Exception as e:
        st.error(f"Erreur lors de la mise √† jour: {e}")
        return df_prepared, False

# Code √† ajouter apr√®s la mise √† jour du mod√®le
#for correction in valid_corrections:
#    test_text = correction['texte']
#    predictions, probabilities = predictor.predict_hierarchy(test_text, prediction_level)
#    st.success(f"Pr√©diction apr√®s mise √† jour pour '{test_text}': {predictions} avec confiance {probabilities}")


@st.cache_data
def load_data(file_data=None):
    """Chargement des donn√©es avec cache"""
    if file_data is not None:
        try:
            df = pd.read_excel(file_data)
            return df
        except Exception as e:
            st.error(f"Erreur lors du chargement du fichier upload√©: {e}")
            return None
    else:
        try:
            data_path = os.path.join("Data", "Data.xlsx")
            if os.path.exists(data_path):
                df = pd.read_excel(data_path)
                return df
            else:
                st.warning(f"Fichier Data.xlsx introuvable dans le dossier Data/")
                return None
        except Exception as e:
            st.warning(f"Erreur lors du chargement de Data/Data.xlsx: {e}")
            return None



def main():
    # Initialisation du pr√©dicteur
#    predictor = EnhancedHierarchicalPredictor()  

    # Afficher uniquement les logos en position fixe
    display_fixed_logos()

    # (No explicit active_tab needed) using 'mode_select' radio to control view

    # Charger le CSS et les √©l√©ments visuels
    load_css()
    
    # CSS FORCE OVERRIDE DIRECT - INJECTION MULTIPLE
    st.markdown("""
    <style>
        /* OVERRIDE ABSOLU - TOUS LES CHAMPS EN NOIR */
        .stSelectbox div[data-baseweb="select"] div,
        .stSelectbox div[role="combobox"],
        .stSelectbox div[data-testid="stSelectbox"] > div > div,
        .stSidebar .stSelectbox div[data-baseweb="select"] div,
        .stSidebar .stSelectbox div[role="combobox"],
        .stSidebar .stSelectbox div[data-testid="stSelectbox"] > div > div {
            background-color: #000000 !important;
            color: #ffffff !important;
            border: none !important;
            box-shadow: 0 0 0 1px rgba(255, 255, 255, 0.1) !important;
        }
        
        /* TEXT AREAS ET INPUTS - FORCE NOIR - TOUS LES SELECTEURS POSSIBLES */
        .stTextArea textarea,
        .stTextInput input,
        .stSidebar .stTextArea textarea,
        .stSidebar .stTextInput input,
        textarea,
        input[type="text"],
        input[type="number"],
        div[data-testid="stTextArea"] textarea,
        div[data-testid="stTextInput"] input,
        [data-testid="textAreaInput"],
        [data-testid="textInput"] {
            background-color: #000000 !important;
            color: #ffffff !important;
            border: none !important;
            box-shadow: 0 0 0 1px rgba(255, 255, 255, 0.1) !important;
        }
        
        /* PLACEHOLDER TEXT */
        textarea::placeholder,
        input::placeholder {
            color: rgba(255, 255, 255, 0.5) !important;
        }
        
        /* SELECTBOX DANS INTERFACE PRINCIPALE - FORCE NOIR */
        div[data-testid="stSelectbox"] div,
        div[data-testid="stSelectbox"] div div,
        .main .stSelectbox div,
        .main .stSelectbox div div,
        .main [data-baseweb="select"],
        .main [data-baseweb="select"] div {
            background-color: #000000 !important;
            color: #ffffff !important;
            border: none !important;
            box-shadow: 0 0 0 1px rgba(255, 255, 255, 0.1) !important;
        }
        
        /* FOCUS STATES */
        .stSelectbox div[data-baseweb="select"] div:focus,
        .stTextArea textarea:focus,
        .stTextInput input:focus,
        div[data-testid="stSelectbox"] div:focus {
            box-shadow: 0 0 0 2px rgba(102, 126, 234, 0.5) !important;
            outline: none !important;
        }
        
        /* HOVER STATES */
        .stSelectbox div[data-baseweb="select"] div:hover,
        .stTextArea textarea:hover,
        .stTextInput input:hover,
        div[data-testid="stSelectbox"] div:hover {
            box-shadow: 0 0 0 1px rgba(255, 255, 255, 0.2) !important;
        }
        
        /* Style pour l'onglet actif */
        .stTabs [aria-selected="true"] {
            background-color: rgba(102, 126, 234, 0.2) !important;
            border-bottom-color: #667eea !important;
        }
        
        .stTabs [aria-selected="true"] p {
            color: #667eea !important;
            font-weight: bold !important;
        }
        
        /* FILE UPLOADER - FORCE NOIR PLUS SPECIFIQUE */
        .stFileUploader section,
        .stFileUploader div[data-testid="stFileUploaderDropzone"],
        .stSidebar .stFileUploader section,
        .stSidebar .stFileUploader div[data-testid="stFileUploaderDropzone"],
        div[data-testid="stFileUploader"] section,
        div[data-testid="stFileUploader"] div {
            background-color: #000000 !important;
            color: #ffffff !important;
            border: none !important;
            box-shadow: 0 0 0 1px rgba(255,255,255,0.04) !important;
        }
        
        /* SIDEBAR BACKGROUND - FORCE NOIR */
        .css-1d391kg,
        .css-1y4p8pa,
        .css-12oz5g7,
        .stSidebar,
        section[data-testid="stSidebar"] {
            background-color: #1a1a1a !important;
        }
        
        /* SIDEBAR TEXT - FORCE BLANC */
        .stSidebar,
        .stSidebar *,
        .stSidebar p,
        .stSidebar label,
        .stSidebar span,
        .stSidebar div {
            color: #ffffff !important;
        }
        
        /* DATAFRAME - FORCE NOIR */
        .stDataFrame,
        .stDataFrame table,
        .stDataFrame tbody tr,
        .stDataFrame td,
        div[data-testid="dataframe"] table,
        div[data-testid="dataframe"] td {
            background-color: #000000 !important;
            color: #ffffff !important;
        }
        
        .stDataFrame th,
        div[data-testid="dataframe"] th {
            background-color: #1a1a1a !important;
            color: #ffffff !important;
        }
        
        /* FORCER TOUS LES DROPDOWNS */
        [role="listbox"],
        [role="option"],
        div[role="listbox"],
        div[role="option"] {
            background-color: #000000 !important;
            color: #ffffff !important;
        }
        
        /* SLIDER */
        .stSlider div {
            color: #ffffff !important;
        }
        
        /* EXPANDER */
        .stExpander,
        .stExpander div,
        div[data-testid="stExpander"] {
            background-color: #000000 !important;
            color: #ffffff !important;
            border: none !important;
            box-shadow: 0 6px 18px rgba(0,0,0,0.45) inset, 0 1px 0 0 rgba(255,255,255,0.02) !important;
        }
    </style>
    """, unsafe_allow_html=True)

    set_background_image("structure.jpg")   ###

    # Corrections CSS cibl√©es pour assurer une lisibilit√© optimale tout en gardant un fond sombre
    st.markdown("""
    <style>
        /* Keep these main selector blocks dark but improve contrast */
        .hierarchy-selector, .batch-section, .update-section {
            background: linear-gradient(135deg, rgba(8,12,20,0.92) 0%, rgba(12,18,30,0.95) 100%) !important;
            color: #ffffff !important;
            border: none !important;
            box-shadow: 0 6px 18px rgba(0,0,0,0.6) inset, 0 2px 8px rgba(0,0,0,0.4) !important;
        }

        /* Ensure textareas and inputs inside these dark sections are readable */
        .hierarchy-selector textarea,
        .batch-section textarea,
        .update-section textarea,
        .hierarchy-selector input,
        .batch-section input,
        .update-section input {
            background: rgba(0,0,0,0.75) !important;
            color: #ffffff !important;
            border: none !important;
            box-shadow: inset 0 1px 0 rgba(255,255,255,0.02) !important;
        }

        /* Keep sidebar expanders dark (affects "üìä Niveaux disponibles") */
        .stSidebar .stExpander {
            background: linear-gradient(180deg, rgba(12,16,22,0.95) 0%, rgba(8,10,14,0.95) 100%) !important;
            color: #ffffff !important;
            border: none !important;
            box-shadow: 0 2px 8px rgba(0,0,0,0.45) !important;
        }

        /* Main expanders keep readable dark style as well */
        .stExpander {
            background: linear-gradient(180deg, rgba(12,16,22,0.95) 0%, rgba(8,10,14,0.95) 100%) !important;
            color: #ffffff !important;
            border: none !important;
            box-shadow: 0 2px 8px rgba(0,0,0,0.45) !important;
        }

        .stSidebar .stExpander > div > div > div, .stExpander > div > div > div {
            color: #ffffff !important;
            font-weight: 600 !important;
        }
    </style>
    """, unsafe_allow_html=True)

    # En-t√™te principal
    # Style pour faire ressembler le radio 'mode_select' √† des onglets
    st.markdown("""
    <style>
    /* Radio -> Tabs visual */
    div[role="radiogroup"]{ display:flex; gap:8px; margin-bottom:0.8rem; border-bottom:1px solid rgba(255,255,255,0.04); padding-bottom:6px; }
    div[role="radiogroup"] > div[role="radio"]{ background:transparent; color:rgba(255,255,255,0.85); padding:6px 14px; border-radius:10px 10px 0 0; cursor:pointer; transition:all .12s ease; }
    div[role="radiogroup"] > div[role="radio"]:hover{ background:rgba(255,255,255,0.03); color:#ffffff; }
    div[role="radiogroup"] > div[role="radio"][aria-checked="true"]{ background:linear-gradient(90deg,#667eea,#764ba2) !important; color:#ffffff !important; font-weight:700 !important; box-shadow:0 6px 18px rgba(0,0,0,0.5) !important; }
    /* Ensure the inner label/text uses full width */
    div[role="radiogroup"] > div[role="radio"] > label{ width:100%; }
    </style>
    """, unsafe_allow_html=True)
    st.markdown("""
    <div class="main-header">
        <h1>Classifieur de l‚Äôactivit√© selon la NACAM</h1>
        <p>Classification intelligente des activit√©s exerc√©es par un agent √©conomique</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar principale
    st.sidebar.markdown("### **üéØ Classifieur de l'activit√©**")
    st.sidebar.markdown("---")
    st.sidebar.title("Configuration")
    
    # Upload du fichier de donn√©es
    st.sidebar.subheader("üìä Donn√©es")
    uploaded_file = st.sidebar.file_uploader(
        "Uploadez votre fichier Excel",
        type=['xlsx', 'xls'],
        help="Fichier contenant les donn√©es de nomenclature"
    )
    
    # Chargement des donn√©es
    if uploaded_file is not None:
        df = load_data(uploaded_file)
    else:
        df = load_data()
    
    if df is None:
        st.markdown("""
        <div class="prediction-result">
            <h3>Aucun fichier de donn√©es disponible</h3>
            <h4>Instructions:</h4>
            <ol>
                <li>Utilisez le bouton "Browse files" dans la sidebar</li>
                <li>S√©lectionnez votre fichier Data.xlsx</li>
                <li>L'application se mettra √† jour automatiquement</li>
            </ol>
        </div>
        """, unsafe_allow_html=True)
        return
    
    # Validation des colonnes
    colonnes_requises = ['reponse', 'langage', 'Classe', 'Grand poste', 'Section', 'Groupe']
    colonnes_manquantes = [col for col in colonnes_requises if col not in df.columns]
    
    if colonnes_manquantes:
        st.sidebar.error(f"Colonnes manquantes: {', '.join(colonnes_manquantes)}")
        st.markdown(f"""
        <div class="prediction-result" style="border-color: #dc3545; background: rgba(220, 53, 69, 0.1);">
            <h3>Structure de fichier incorrecte</h3>
            <p><strong>Colonnes manquantes:</strong> {', '.join(colonnes_manquantes)}</p>
            <p><strong>Colonnes trouv√©es:</strong> {', '.join(df.columns.tolist())}</p>
        </div>
        """, unsafe_allow_html=True)
        return
    else:
        st.sidebar.success(f"Fichier valide - {len(df):,} entr√©es charg√©es")
    
    # Configuration des mod√®les
    st.sidebar.subheader("‚öôÔ∏è Configuration")
    
    # Options avanc√©es
    st.sidebar.markdown("#### Options d'optimisation")
    use_smote = st.sidebar.checkbox("Activer SMOTE (sur√©chantillonnage)", value=True, 
                                   help="Corrige les d√©s√©quilibres de classes")
    
    # S√©lection du niveau de pr√©diction
    prediction_level = st.sidebar.selectbox(
        "Niveau de pr√©diction maximum",
        options=['Grand poste', 'Section', 'Groupe', 'Classe'],
        index=3,
        help="Niveau hi√©rarchique jusqu'auquel pr√©dire"
    )
    
    # Information sur le mod√®le disponible (CPU optimis√©)
    st.sidebar.markdown("#### ü§ñ Mod√®le utilis√©")
#    st.sidebar.info("**MultinomialNB** - Optimis√© pour CPU")
    st.sidebar.markdown("*Param√®tres optimis√©s automatiquement*")
    
    # Initialisation du pr√©dicteur
    predictor = EnhancedHierarchicalPredictor()
    predictor.use_smote = use_smote
    
    # Pr√©parer les donn√©es et construire la structure hi√©rarchique
    df_prepared = predictor.prepare_data(df, prediction_level)
    
    # S√©lecteurs hi√©rarchiques dans la sidebar
    hierarchy_selections = create_hierarchy_selector(df_prepared, predictor)
    
    # Affichage des informations sur les s√©lections
    if hierarchy_selections:
        st.sidebar.markdown("### üìã S√©lections Actuelles")
        for level, selection in hierarchy_selections.items():
            st.sidebar.markdown(f"**{level}:** {selection}")
        
        # V√©rifier si c'est un cas unique
        if hasattr(predictor, 'hierarchy_structure'):
            is_unique, unique_class = predictor.get_unique_prediction_path(hierarchy_selections)
            if is_unique:
                st.sidebar.success("‚úÖ Classification unique identifi√©e")
    
    # Gestion de l'entra√Ænement des mod√®les
    data_hash = predictor.get_data_hash(df_prepared)
    model_filename = predictor.get_model_filename(data_hash, prediction_level)
    
    st.sidebar.subheader("üß† Gestion des Mod√®les")
    models_exist = predictor.models_exist(model_filename)
    
    if models_exist:
        st.sidebar.success("Mod√®les trouv√©s")
        use_saved = st.sidebar.checkbox("Utiliser mod√®les sauvegard√©s", value=True)
        force_retrain = st.sidebar.button("üîÑ Re-entra√Æner")
    else:
        use_saved = False
        force_retrain = False
    
    # Cache pour les mod√®les
    cache_key = f"enhanced_predictor_{prediction_level}_{data_hash}_{use_smote}"
    
    # Entra√Ænement ou chargement
    if models_exist and use_saved and not force_retrain:
        if cache_key not in st.session_state:
            with st.spinner("Chargement des mod√®les..."):
                try:
                    if predictor.load_models(model_filename):
                        st.session_state[cache_key] = {
                            'predictor': predictor,
                            'df_prepared': df_prepared
                        }
                        st.sidebar.success("Mod√®les charg√©s avec succ√®s")
                except Exception as e:
                    st.sidebar.error(f"Erreur de chargement: {e}")
                    force_retrain = True
    
    if cache_key not in st.session_state or force_retrain:
        with st.spinner("Entra√Ænement des mod√®les en cours..."):
#            st.info("üöÄ Optimisation MultinomialNB en cours...")
            
            try:
                predictor.train_hierarchical_models(df_prepared, prediction_level)
                
                # Sauvegarder
                predictor.save_models(model_filename)
                
                st.session_state[cache_key] = {
                    'predictor': predictor,
                    'df_prepared': df_prepared
                }
                
            #    st.balloons()
                
            except Exception as e:
                st.error(f"Erreur lors de l'entra√Ænement: {e}")
                return
    
    predictor = st.session_state[cache_key]['predictor']
    df_prepared = st.session_state[cache_key]['df_prepared']
    
    # Interface principale avec deux colonnes principales
    main_col1, main_col2 = st.columns([3, 1])
    
    with main_col1:
        st.header("üéØ Mode de Pr√©diction")
        
        # Mode selector (replace programmatic tabs to keep selection stable across reruns)
        mode = st.radio(
            "Onglet",
            ["Pr√©diction Manuelle", "Pr√©diction par Lot", "Mise √† Jour Mod√®le"],
            index=0,
            key="mode_select",
            horizontal=True,
        )

        # Render sections conditionally based on selected mode
        if st.session_state.get("mode_select", "Pr√©diction Manuelle") == "Pr√©diction Manuelle":
            st.markdown("""
            <div class="hierarchy-selector">
                <h4>‚úçÔ∏è Pr√©diction Manuelle</h4>
                <p>Entrez un texte pour obtenir sa classification hi√©rarchique</p>
            </div>
            """, unsafe_allow_html=True)
            
            user_input = st.text_area(
                "Entrez votre texte √† classifier:",
                placeholder="Ex: Culture de bl√©, Fabrication de meubles, Services bancaires...",
                height=100,
                key="manual_input"
            )
            
            col_predict, col_guided = st.columns(2)
            
            with col_predict:
                predict_button = st.button("üéØ Pr√©diction Libre", type="primary")
            
            with col_guided:
                guided_button = st.button("üß≠ Pr√©diction Guid√©e", help="Utilise les s√©lections de la sidebar", type="primary")
            
            if predict_button and user_input:
                with st.spinner("Analyse en cours..."):
                    try:
                        predictions, probabilities = predictor.predict_hierarchy(user_input, prediction_level)
                        
                        st.markdown("### üìä R√©sultats de la pr√©diction")
                        
                        hierarchy_levels = ['Grand poste', 'Section', 'Groupe', 'Classe']
                        display_levels = hierarchy_levels[:hierarchy_levels.index(prediction_level) + 1]
                        colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4']
                        
                        for i, level in enumerate(display_levels):
                            if level in predictions:
                                confidence = probabilities[level]
                                conf_class = "confidence-high" if confidence > 0.8 else "confidence-medium" if confidence > 0.6 else "confidence-low"
                                conf_text = "√âlev√©e" if confidence > 0.8 else "Moyenne" if confidence > 0.6 else "Faible"
                                conf_icon = "‚úÖ" if confidence > 0.8 else "‚ö†Ô∏è" if confidence > 0.6 else "‚ùå"
                                
                                st.markdown(f"""
                                <div class="level-card">
                                    <h4 style="color: {colors[i]}; margin: 0 0 0.5rem 0;">
                                        {level}
                                    </h4>
                                    <p style="font-size: 1.1rem; margin: 0.5rem 0;">
                                        <strong>{predictions[level]}</strong>
                                    </p>
                                    <p style="margin: 0;">
                                        Confiance: <span class="{conf_class}">{confidence:.2%}</span> ({conf_text}) {conf_icon}
                                    </p>
                                </div>
                                """, unsafe_allow_html=True)
                        
                        # Graphique des probabilit√©s
                        valid_levels = [level for level in display_levels 
                                      if predictions.get(level) not in ["Mod√®le non disponible", "Erreur de pr√©diction"]]
                        
                        if valid_levels:
                            fig = go.Figure(data=[
                                go.Bar(
                                    x=valid_levels,
                                    y=[probabilities[level] for level in valid_levels],
                                    marker_color=[colors[hierarchy_levels.index(level)] for level in valid_levels],
                                    text=[f"{probabilities[level]:.2%}" for level in valid_levels],
                                    textposition='auto'
                                )
                            ])
                            
                            fig.update_layout(
                                title=f"Niveaux de confiance - Pr√©diction {prediction_level}",
                                xaxis_title="Niveaux hi√©rarchiques",
                                yaxis_title="Niveau de confiance",
                                yaxis=dict(tickformat=".0%"),
                                height=400,
                                plot_bgcolor='rgba(0,0,0,0)',
                                paper_bgcolor='rgba(0,0,0,0)'
                            )
                            
                            st.plotly_chart(fig, use_container_width=True)
                        
                    except Exception as e:
                        st.error(f"Erreur lors de la pr√©diction: {e}")
            
            if guided_button and user_input:
                with st.spinner("Analyse guid√©e en cours..."):
                    try:
                        predictions, probabilities = predictor.predict_hierarchy(user_input, prediction_level)
                        
                        # D√©finir les niveaux hi√©rarchiques pour l'analyse
                        hierarchy_levels = ['Grand poste', 'Section', 'Groupe', 'Classe']
                        target_hierarchy_levels = hierarchy_levels[:hierarchy_levels.index(prediction_level) + 1]
                        
                        # Cr√©er l'analyse comparative avec les s√©lections
                        create_prediction_analysis(predictions, probabilities, target_hierarchy_levels, hierarchy_selections)
                        
                    except Exception as e:
                        st.error(f"Erreur lors de la pr√©diction guid√©e: {e}")
        
    if st.session_state.get("mode_select", "Pr√©diction Manuelle") == "Pr√©diction par Lot":
            st.markdown("""
            <div class="batch-section">
                <h4>üìÇ Pr√©diction par Lot</h4>
                <p>Uploadez un fichier contenant plusieurs textes √† classifier</p>
            </div>
            """, unsafe_allow_html=True)
            
            # G√©rer le changement d'onglet quand un fichier est upload√©
            def on_file_upload():
                # When a batch file is uploaded, set the mode radio to the batch view
                st.session_state["mode_select"] = "Pr√©diction par Lot"

            uploaded_batch_file = st.file_uploader(
                "Choisissez votre fichier",
                type=['csv', 'xlsx', 'xls', 'txt'],
                help="Formats support√©s: CSV, Excel, TXT",
                key="batch_file",
                on_change=on_file_upload
            )
            
            if uploaded_batch_file is not None:
                col_config1, col_config2 = st.columns(2)
                
                with col_config1:
                    if uploaded_batch_file.name.endswith('.txt'):
                        text_column = "texte"
                        st.info("Fichier TXT d√©tect√© - une ligne = un texte")
                    else:
                        try:
                            if uploaded_batch_file.name.endswith('.csv'):
                                preview_df = pd.read_csv(uploaded_batch_file, nrows=3)
                            else:
                                preview_df = pd.read_excel(uploaded_batch_file, nrows=3)
                            
                            text_column = st.selectbox(
                                "Colonne contenant les textes:",
                                options=preview_df.columns.tolist(),
                                key="text_column_select"
                            )
                            
                            st.markdown("**Aper√ßu du fichier:**")
                            st.dataframe(preview_df, use_container_width=True)
                            
                        except Exception as e:
                            st.error(f"Erreur lors de la lecture du fichier: {e}")
                            text_column = None
                
                with col_config2:
                    batch_size = st.slider(
                        "Taille du lot:",
                        min_value=10,
                        max_value=500,
                        value=100
                    )
                
                if st.button("üìÇ Traiter le lot", type="primary") and text_column:
                    with st.spinner("Traitement du fichier en cours..."):
                        df_batch, texts_batch, error = process_batch_file(uploaded_batch_file, text_column)
                        
                        if error:
                            st.error(f"Erreur: {error}")
                        elif texts_batch:
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            
                            total_texts = len(texts_batch)
                            all_predictions = []
                            all_probabilities = []
                            
                            for i in range(0, total_texts, batch_size):
                                batch_texts = texts_batch[i:i + batch_size]
                                status_text.text(f"Traitement: {i + 1}-{min(i + batch_size, total_texts)} sur {total_texts}")
                                
                                try:
                                    for text in batch_texts:
                                        pred, prob = predictor.predict_hierarchy(text, prediction_level)
                                        all_predictions.append(pred)
                                        all_probabilities.append(prob)
                                except Exception as e:
                                    st.error(f"Erreur lors du traitement: {e}")
                                    break
                                
                                progress_bar.progress(min(1.0, (i + batch_size) / total_texts))
                            
                            progress_bar.empty()
                            status_text.empty()
                            
                            if all_predictions:
                                st.success(f"Traitement termin√©! {len(all_predictions)} textes classifi√©s")
                                
                                results_df = create_batch_results_table(
                                    texts_batch, all_predictions, all_probabilities, prediction_level
                                )
                                
                                st.markdown("### üìä R√©sultats de la classification par lot")
                                st.dataframe(results_df, use_container_width=True, height=400)
                                
                                # Options d'exportation
                                with st.expander("üì• Options d'exportation", expanded=True):
                                    export_col1, export_col2 = st.columns([1, 2])
                                    
                                    with export_col1:
                                        export_format = st.selectbox(
                                            "Format d'export",
                                            options=["Excel (.xlsx)", "CSV (.csv)"],
                                            index=0,
                                            help="Choisissez le format du fichier d'export"
                                        )
                                    
                                    with export_col2:
                                        include_confidence = st.checkbox("‚úì Niveaux de confiance", 
                                            value=True,
                                            help="Inclure les scores de confiance pour chaque pr√©diction")
                                        include_source = st.checkbox("‚úì Donn√©es sources", 
                                            value=True,
                                            help="Inclure les textes originaux et pr√©trait√©s")
                                        include_metadata = st.checkbox("‚úì M√©tadonn√©es", 
                                            value=True,
                                            help="Inclure les informations sur le mod√®le et la date de pr√©diction")

                                    # Bouton d'export unique qui d√©clenchera l'action
                                    export_clicked = st.button("üíæ Exporter les r√©sultats", use_container_width=True)

                                    # Ne proc√©der √† l'export que si le bouton est cliqu√©
                                    if export_clicked:
                                        # Pr√©paration des donn√©es pour l'export
                                        export_df = results_df.copy()
                                
                                # Pr√©paration des donn√©es d'export
                                export_df = results_df.copy()
                                
                                # Ajout minimal des m√©tadonn√©es (date/heure) si demand√©
                                metadata_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                if include_metadata:
                                    # Ajouter une colonne Date_prediction pour tra√ßabilit√©
                                    export_df['Date_prediction'] = metadata_date
                                
                                # Suppression des colonnes si non demand√©es
                                if not include_confidence:
                                    confidence_cols = [col for col in export_df.columns if 'confiance' in col.lower() or 'probabilit√©' in col.lower()]
                                    export_df = export_df.drop(columns=confidence_cols, errors='ignore')
                                
                                if not include_source:
                                    source_cols = ['texte_original', 'texte_pretraite']
                                    export_df = export_df.drop(columns=[col for col in source_cols if col in export_df.columns])
                                
                                # Initialiser les variables de session pour les options d'export si elles n'existent pas
                                if 'export_format' not in st.session_state:
                                    st.session_state.export_format = export_format
                                if 'include_metadata' not in st.session_state:
                                    st.session_state.include_metadata = include_metadata

                                # Export selon le format choisi
                                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                                if st.session_state.export_format == "Excel (.xlsx)":
                                    output = BytesIO()
                                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                                        export_df.to_excel(writer, index=False, sheet_name='Pr√©dictions')

                                        # Feuille de m√©tadonn√©es (date/heure uniquement)
                                        if include_metadata:
                                            pd.DataFrame([{'Date_prediction': metadata_date}]).to_excel(
                                                writer,
                                                sheet_name='M√©tadonn√©es',
                                                index=False
                                            )

                                        # Appliquer le style conditionnel aux colonnes de confiance
                                        try:
                                            workbook = writer.book
                                            worksheet = writer.sheets['Pr√©dictions']

                                            # D√©finir les fills
                                            high_fill = PatternFill(start_color="FF28A745", end_color="FF28A745", fill_type="solid")
                                            medium_fill = PatternFill(start_color="FFFFC107", end_color="FFFFC107", fill_type="solid")
                                            low_fill = PatternFill(start_color="FFFF6B6B", end_color="FFFF6B6B", fill_type="solid")

                                            # Parcourir les colonnes pour trouver celles de confiance
                                            for idx, col in enumerate(export_df.columns, start=1):
                                                if 'confiance' in col.lower() or 'probabilit√©' in col.lower():
                                                    col_letter = get_column_letter(idx)
                                                    for row_idx in range(2, len(export_df) + 2):
                                                        cell = worksheet[f"{col_letter}{row_idx}"]
                                                        val = cell.value
                                                        v = None
                                                        # G√©rer les formats '12.34%' ou valeurs num√©riques
                                                        try:
                                                            if isinstance(val, str) and val.strip().endswith('%'):
                                                                v = float(val.strip().replace('%', '')) / 100.0
                                                            else:
                                                                v = float(val)
                                                        except Exception:
                                                            v = None

                                                        if v is not None:
                                                            if v > 0.8:
                                                                cell.fill = high_fill
                                                            elif v > 0.6:
                                                                cell.fill = medium_fill
                                                            else:
                                                                cell.fill = low_fill
                                        except Exception as e:
                                            # Si le styling √©choue, on ne bloque pas l'export
                                            import traceback
                                            traceback.print_exc()

                                    excel_data = output.getvalue()
                                    st.download_button(
                                        label="üíæ T√©l√©charger les r√©sultats (Excel)",
                                        data=excel_data,
                                        file_name=f"predictions_hierarchiques_{timestamp}.xlsx",
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                    )
                                else:
                                    csv_data = export_df.to_csv(index=False)
                                    st.download_button(
                                        label="üíæ T√©l√©charger les r√©sultats (CSV)",
                                        data=csv_data,
                                        file_name=f"predictions_hierarchiques_{timestamp}.csv",
                                        mime="text/csv"
                                    )
                        else:
                            st.warning("Aucun texte trouv√© dans le fichier")
        

    if st.session_state.get("mode_select", "Pr√©diction Manuelle") == "Mise √† Jour Mod√®le":
        st.markdown("""
        <div class="update-section">
            <h4>üîÑ Mise √† Jour du Mod√®le</h4>
            <p>Corrigez les pr√©dictions incorrectes pour am√©liorer le mod√®le</p>
        </div>
        """, unsafe_allow_html=True)
    
        st.markdown("#### Ajouter une correction")
    
        # ‚úÖ Initialiser les cl√©s hi√©rarchiques vides dans la session
        for key in ["correct_gp", "correct_section", "correct_groupe", "correct_classe"]:
            st.session_state.setdefault(key, "")
    
        col_text, col_correct = st.columns([2, 1])
    
        # üßæ Zone de texte pour le texte mal pr√©dit
        with col_text:
            correction_text = st.text_area(
                "Texte mal pr√©dit:",
                placeholder="Entrez le texte qui a √©t√© mal classifi√©...",
                height=80,
                key="correction_text"
            )
    
        # üß© S√©lecteurs hi√©rarchiques
        with col_correct:
            st.markdown("**Classifications correctes:**")
    
            correct_grand_poste = st.selectbox(
                "Grand poste correct:",
                options=[""] + sorted(df_prepared['Grand poste'].unique()),
                key="correct_gp"
            )
    
            filtered_sections = (
                df_prepared[df_prepared['Grand poste'] == correct_grand_poste]['Section'].unique()
                if correct_grand_poste else []
            )
            correct_section = st.selectbox(
                "Section correcte:",
                options=[""] + sorted(filtered_sections),
                key="correct_section"
            )
    
            filtered_groups = (
                df_prepared[
                    (df_prepared['Grand poste'] == correct_grand_poste) &
                    (df_prepared['Section'] == correct_section)
                ]['Groupe'].unique()
                if correct_section else []
            )
            correct_groupe = st.selectbox(
                "Groupe correct:",
                options=[""] + sorted(filtered_groups),
                key="correct_groupe"
            )
    
            filtered_classes = (
                df_prepared[
                    (df_prepared['Grand poste'] == correct_grand_poste) &
                    (df_prepared['Section'] == correct_section) &
                    (df_prepared['Groupe'] == correct_groupe)
                ]['Classe'].unique()
                if correct_groupe else []
            )
            correct_classe = st.selectbox(
                "Classe correcte:",
                options=[""] + sorted(filtered_classes),
                key="correct_classe"
            )
    
        # ---------- Initialiser la liste des corrections ----------
        if "corrections" not in st.session_state:
            st.session_state.corrections = []
    
        # ---------- Colonnes d'action ----------
        col_add, col_train = st.columns(2)
    
        with col_add:
            if st.button("‚ûï Ajouter Correction"):
                correction_text = st.session_state.get("correction_text", "").strip()
                correct_grand_poste = st.session_state.get("correct_gp", "").strip()
                correct_section = st.session_state.get("correct_section", "").strip()
                correct_groupe = st.session_state.get("correct_groupe", "").strip()
                correct_classe = st.session_state.get("correct_classe", "").strip()
    
                if not correction_text:
                    st.error("‚ùó Le texte de la correction est vide.")
                elif not all([correct_grand_poste, correct_section, correct_groupe, correct_classe]):
                    st.error("‚ùó Veuillez s√©lectionner tous les niveaux hi√©rarchiques (Grand poste / Section / Groupe / Classe).")
                else:
                    correction = {
                        "texte": correction_text,
                        "Grand poste": correct_grand_poste,
                        "Section": correct_section,
                        "Groupe": correct_groupe,
                        "Classe": correct_classe,
                    }
                    st.session_state.corrections.append(correction)
                    st.success("‚úÖ Correction ajout√©e avec succ√®s !")
    
                    # üîÑ R√©initialiser les champs pour faciliter la saisie suivante
                    #st.session_state.correction_text = ""
                    #st.session_state.correct_gp = ""
                    #st.session_state.correct_section = ""
                    #st.session_state.correct_groupe = ""
                    #st.session_state.correct_classe = ""
    

        with col_train:
            if st.button("üîÑ Mettre √† jour le mod√®le", type="primary"):
                corrections = st.session_state.get("corrections", [])
                if not corrections:
                    st.info("‚ÑπÔ∏è Aucune correction en attente.")
                else:
                    valid_corrections = []  # INITIALISATION ICI
                    invalid_entries = 0

                    # Validation des champs de chaque correction
                    for corr in corrections:
                        for k in ["Grand poste", "Section", "Groupe", "Classe", "texte"]:
                            corr[k] = str(corr.get(k, "")).strip()
                        if all(corr.get(k) for k in ["Grand poste", "Section", "Groupe", "Classe", "texte"]):
                            valid_corrections.append(corr)
                        else:
                            invalid_entries += 1

                    if invalid_entries > 0:
                        st.warning(f"‚ö†Ô∏è {invalid_entries} correction(s) ignor√©e(s) car incompl√®tes.")
                    if not valid_corrections:
                        st.error("üö´ Aucune correction valide √† int√©grer. V√©rifiez les champs hi√©rarchiques et le texte.")
                    else:
                        with st.spinner("Mise √† jour du mod√®le en cours..."):
                            df_prepared, updated = update_model_with_corrections(
                                predictor, df_prepared, valid_corrections, prediction_level
                            )
                        if updated:
                            st.success("üéØ Mod√®le mis √† jour avec succ√®s avec les corrections valides !")
                            # Optionnel : vider les corrections apr√®s mise √† jour
                            st.session_state.corrections = []

                            # Validation des nouvelles pr√©dictions
#                            for correction in valid_corrections:
#                                test_text = correction['texte']
#                                predictions, probabilities = predictor.predict_hierarchy(test_text, prediction_level)
#                                st.success(f"Pr√©diction apr√®s mise √† jour pour '{test_text}': {predictions} avec confiance {probabilities}")


                            st.markdown("### üîç Analyse des Pr√©dictions apr√®s Mise √† Jour")
                            for correction in valid_corrections:
                                test_text = correction['texte']
                                actual_class = correction['Classe']
                                predictions, probabilities = predictor.predict_hierarchy(test_text, prediction_level)
                                
                                st.write(f"Texte: {test_text}")
                                st.write(f"Pr√©diction: {predictions} avec confiance {probabilities}")
                                st.write(f"Classe r√©elle: {actual_class}")

#        with col_train:
#            if st.button("üîÑ Mettre √† jour le mod√®le", type="primary"):
#                corrections = st.session_state.get("corrections", [])
#                if not corrections:
#                    st.info("‚ÑπÔ∏è Aucune correction en attente.")
#                else:
#                    valid_corrections = []
#                    invalid_entries = 0
#    
#                    # Validation des champs de chaque correction
#                    for corr in corrections:
#                        for k in ["Grand poste", "Section", "Groupe", "Classe", "texte"]:
#                            corr[k] = str(corr.get(k, "")).strip()
#                        if all(corr.get(k) for k in ["Grand poste", "Section", "Groupe", "Classe", "texte"]):
#                            valid_corrections.append(corr)
#                        else:
#                            invalid_entries += 1
#    
#                    if invalid_entries > 0:
#                        st.warning(f"‚ö†Ô∏è {invalid_entries} correction(s) ignor√©e(s) car incompl√®tes.")
#                    if not valid_corrections:
#                        st.error("üö´ Aucune correction valide √† int√©grer. V√©rifie les champs hi√©rarchiques et le texte.")
#                    else:
#                        with st.spinner("Mise √† jour du mod√®le en cours..."):
#                            df_prepared, updated = update_model_with_corrections(
#                                predictor, df_prepared, valid_corrections, prediction_level
#                            )
#                        if updated:
#                            st.success("üéØ Mod√®le mis √† jour avec succ√®s avec les corrections valides !")
                            # Optionnel : vider les corrections apr√®s mise √† jour
                            # st.session_state.corrections = []
    
        # ---------- Affichage des corrections ----------
        if st.session_state.corrections:
            st.markdown("#### Corrections en attente:")
            for i, correction in enumerate(st.session_state.corrections):
                with st.expander(f"Correction {i+1}: {correction['texte'][:50]}..."):
                    st.json(correction)
                    if st.button(f"üóëÔ∏è Supprimer", key=f"delete_{i}"):
                        st.session_state.corrections.pop(i)
                        st.experimental_rerun()
    

    with main_col2:
        # N'afficher les informations que si nous ne sommes pas dans le mode 'Pr√©diction par Lot'
        if st.session_state.get("mode_select", "Pr√©diction Manuelle") not in ["Pr√©diction par Lot","Mise √† Jour Mod√®le"]:
            st.header("‚ÑπÔ∏è Informations")
            
            # Informations sur les niveaux uniquement
            hierarchy_levels = ['Grand poste', 'Section', 'Groupe', 'Classe']
            for level in hierarchy_levels:
                unique_count = df_prepared[level].nunique()
                st.markdown(f"""
                <div class="hierarchy-info">
                    <strong>{level}</strong><br>
                    üìä {unique_count} cat√©gories
                </div>
                """, unsafe_allow_html=True)
        
        # Informations sur le mod√®le
        
        # S√©lections actuelles
        if hierarchy_selections:
            st.markdown("### üéØ S√©lections Actuelles")
            for level, selection in hierarchy_selections.items():
                st.markdown(f"**{level}:** {selection}")
            
            # V√©rifier si c'est un cas unique
            if hasattr(predictor, 'hierarchy_structure'):
                is_unique, unique_class = predictor.get_unique_prediction_path(hierarchy_selections)
                if is_unique:
                    st.success("‚úÖ Classification unique identifi√©e")
        
        # Corrections en attente
        if 'corrections' in st.session_state and st.session_state.corrections:
            st.markdown("### üîÑ Corrections en Attente")
            st.info(f"{len(st.session_state.corrections)} correction(s) en attente")
        
        # Aide (ne pas afficher dans le mode de pr√©diction par lot)
        if st.session_state.get("mode_select", "Pr√©diction Manuelle") != "Pr√©diction par Lot":
            with st.expander("‚ùì Aide", expanded=False):
                st.markdown("""
                **Pr√©diction Manuelle:**
                - Libre: Pr√©diction sans contrainte
                - Guid√©e: Utilise vos s√©lections
                
                **Pr√©diction par Lot:**
                - Uploadez CSV, Excel ou TXT
                - Traitez plusieurs textes
                
                **Mise √† Jour:**
                - Corrigez les erreurs de pr√©diction
                - Am√©liorez le mod√®le en continu
                """)
    
    # Footer simplifi√©
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; padding: 1rem;">
        <p style="color: rgba(255,255,255,0.8); font-size: 0.9rem;">
            üéØ Pr√©dicteur Hi√©rarchique MultinomialNB - Optimis√© CPU
        </p>
        <p style="color: rgba(255,255,255,0.6); font-size: 0.8rem;">
            Fonctionnalit√©s: Pr√©diction manuelle ‚Ä¢ Traitement par lot ‚Ä¢ Mise √† jour continue
        </p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":

    main()

